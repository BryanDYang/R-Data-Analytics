---
title: "MBA561 K002 - Team Final Project"
author: "Shawn Abdian, Lexie Brown, Sharon Buller, Neelavathi Jeyakumar, Bryan Yang"
output: html_document
date: 'May 10, 2022'
---

## Task 1. 
__Load the libraries that you will use in this project. __

```{r}
library(dplyr)  
library(magrittr)
library(lubridate) 
library(stringr)  
library(tidyr)
```


## Task 2. 
__Read in the data from the ities.csv and max_temp.csv files as dataframe objects df and df_weather_weekly respectively. __

```{r}
df <- read.csv("ities.csv", stringsAsFactors = T)
df_weather_weekly <- read.csv("max_temp.csv")
```


## Task 3. 
__(1 point) Use an appropriate R function to display the number of rows and columns in the df and df_weather dataframes.__

```{r}
dim(df)
dim(df_weather_weekly)
```
**Answer**:   **df** has 438,151 rows and 13 columns and **df_weather_weekly** has 52 rows and 9 columns. 


## Task 4. 
__(4 points) Using any functions you want, make any necessary datatype conversions to columns in df and/or df_weather_weekly. Display the structures of the dataframes, df and df_weather_weekly to verify that the datatype conversions, if any, worked. Below the output, comment on why you did or did not make datatype conversions. __

(Hint: You may want to come back to this task and update it once you start working on the subsequent tasks.)  

```{r}
#Step 1 - Delete Week column 
df_weather_weekly$Week <- NULL

#Step 2 - Relocate the WeekStarting as the first column 
df_weather_weekly <- df_weather_weekly %>% relocate(WeekStarting, .before = Monday)

#Step 3 - Convert date column as a Date data type for both df and df_weather_weekly dataframe 
df$Date <- mdy(df$Date)
df_weather_weekly$WeekStarting <- mdy(df_weather_weekly$WeekStarting)

#Step 4 - Re-arrange the df dataframe in an ascending date order similar to df_weather_weekly dataframe
df <- df %>% arrange(Date)

#Step 5 - Filter out the RETURNs and only keep the SALEs line items 
summary(df$OperationType)
df <- df %>% filter(OperationType %in% c('SALE'))

#Display the structures of the dataframes, df and df_weather_weekly to verify that the datatype conversions
str(df)
str(df_weather_weekly)
```
**Answer:**  We did not change 'Department', 'LineItem', and 'Category' since they will not be used in the calculations or any of the comparisons.  We have decided to perform the following steps so it will help us to find a relationship (if any) in "Daily Sales" amoung the quantiy purchased, the price paid, and the maxium temperature: 

Step 1: Deletes "Week" column from 'df_weather_weekly' since we do not need the number of week counters in this project, therefore, to simplify the dataframe, the "Week" column is deleted.

Step 2: Relocates the "WeekStarting" as the first column in 'df_weather_weekly'.    

Step 3: By converting the Date columns as the 'date type', we can easily compare and calculate according for 'df' and 'df_weather_week' dataframe in succeeding tasks.

Step 4: Currently, the 'df' dataframe is sorted in a descending date order.   We need to re-arrange the 'df' in ascending date order similar to the 'df_weather_weekly' dataframe.

Step 5: There are two operation types, RETRUN and SALE.  There are 349 returns and 437,802 sales.  We want to filter out the RETURNs and only keep the SALEs, since we want to find out if there is a relationship in "daily sales" among the quantity purchased, the price paid, and the maximum temperature.



## Task 5. 
__(1 point) Display summaries of the columns in the dataframes, df and df_weather_weekly. __

```{r}
summary(df)
summary(df_weather_weekly)
```


## Task 6. 
__(3 points) Display the count of missing values in each column of df. Choose to remove or impute the missing values and defend that choice in 1-2 sentences for each column with missing values. __

```{r}
colSums(is.na(df))                   # display # of rows with missing values in each column of df
df %<>% filter(!is.na(Price)) 
```
**Answer:** There are 437,802 SALE line items in the df dataset.  Of the 437,802 SALE line items, only 12 of the line items have NA in the Price and the TotalDue, which is a very small percentage and most likely due to an error.  By removing these 12 lines, it will NOT diminish or heighten the effect of the outliers.  Therefore, we can remove these line items instead of imputing the missing values. 

## Task 7. 
__(4 points) Let’s now explore whether there is a relationship in daily sales among the quantity purchased, the price paid, and the maximum temperature. To do so, we will want to aggregate the data at the daily level. Thus, please start by creating a new dataset df_daily by aggregating the dataframe df at the daily level. The dataframe df_daily must have the columns Quantity and TotalDue from df summarized at the daily level. Display a summary of df_daily. In one to two sentences defend the choice of summary measure (sum, mean, or other) used to aggregate the values in each column.__ 

```{r}
#Making df_daily from df by aggregating the dataframe at the daily level
df_daily <- df %>%
  mutate(
    date = round_date(Date, 'day')
  ) %>%
  group_by(Date) %>%
  summarise(
    AvgPrice = mean(Price)
    , MedPrice = median(Price, na.rm = T)
    , Quantity = n()
    , TotalDue = sum(TotalDue, na.rm = T)
  ) %>%
  ungroup()
summary(df_daily)
```
**Answer**:  We have decided to summarize the following five variables in df_daily:  Date, AvgPrice, MedPrice, Quantity, and TotalDue. Date is the primary key.  The Average and the Median prices show the observable patterns of the sale items on a daily basis (i.e in majority of the days, the Median daily price of a line item is 11.29 and the Median total sale amount is 5,985).  The Quantity shows the total number of Sale items that are sold each day.  The TotalDue shows the Total Sales amount for each day. (i.e. in majority of the days, the Median sales items sold is 407 and the Median total sales amount is 5,985 dollars.    


## Task 8. 
__(4 points) Create a new dataframe, df_weather_daily, by pivoting the dataframe  df_weather_weekly from wide to long such that names of the seven columns (Monday:Sunday) are in a new column day and the values from those seven columns (Monday:Sunday) are in a new column max_temp. Display the first 10 rows of df_weather_daily to verify that the pivot worked.__

```{r}
# Convert df_weather_weekly to df_weather_daily by pivoting the dataframe from wide to long
df_weather_daily <- df_weather_weekly %>%
  pivot_longer(cols = c(Monday:Sunday)       
              , names_to = 'DayoftheWeek'
              , values_to = 'MaxTemp')

# Display the first 10 rows to verify the pivot worked
df_weather_daily[1:10,]
```


## Task 9. 
__(4 points) Update the df_weather_daily dataframe by adding a column, Date, that corresponds to the value in the day column. For example, if the WeekStarting value is “2016-01-03”, then the value in the Date column for the Monday that comes after “2016-01-03” should have a value of “2016-01-04”. Arrange df_weather_daily in ascending order of Date and display the first 10 rows to verify that it worked. Beneath the output comment on how you know that the creation of the Date column worked.__ 

```{r}
# calculate numeric value that corresponds to the value in the day column
df_weather_daily <- df_weather_daily %>% 
  mutate(                                            
   Day_num = case_when(
    DayoftheWeek == 'Sunday' ~ '0'
    , DayoftheWeek == 'Monday' ~ '1'
    , DayoftheWeek == 'Tuesday' ~ '2'
    , DayoftheWeek == 'Wednesday' ~ '3'
    , DayoftheWeek == 'Thursday' ~ '4'
    , DayoftheWeek == 'Friday' ~ '5'
    , DayoftheWeek == 'Saturday' ~ '6'
    )
  , Date = WeekStarting + as.numeric(Day_num)        # calculate Date corresponds to the value in the day column
  ) %>% 
  arrange(Date) %>%                                  # arrange df_weather_daily in ascending order of the dates 
  relocate(Date, .before = WeekStarting)             # relocate Date in the first column

df_weather_daily$Day_num <- NULL                     # get rid of Day_num col

df_weather_daily[1:10,]                              # show the first 10 rows to verify.
```
**Answer:** The first 10 rows reflect the corrected date of the week.   Jan 3, 2016 is a Sunday.  Jan 4, 2016 is a Monday and so forth.   


## Task 10. 
__(2 points) Join the dataframes df_daily and df_weather_daily into one dataframe df_final such that only the rows that are in both df_daily and  df_weather_daily are in df_final. Arrange df_final in ascending order of Date. Then display something to show that the join worked. Briefly identify how that output helps you know that the join worked.   __

```{r}
#Join the dataframes in a way that only the rows that are in both dataframes in acending order of date.
df_final <- df_daily %>% inner_join(df_weather_daily, by = 'Date')

#Disable WeekStarting on the df_final
df_final$WeekStarting <- NULL

#Relocate DayoftheWeek column to the second column.
df_final <- df_final %>% relocate(DayoftheWeek, .after = Date)

#Show first 10 rows from df_final
df_final[1:10,]
```

**Answer: ** Looking at the summary output of df_final, it shows the date range from 2016-01-05 to 2016-12-31. The total 311 dates listed in df_final are observed in both df_daily and df_weather_daily.


## Task 11. 
__(4 points) Display a pairplot like the one demonstrated towards the end of the module 2 video, “Getting to Know Your Data 3: Summary Statistics for Each Column, and Quick Plots”. Create this pairplot for three columns from df_final: Quantity, TotalDue, and max_temp. Below the output, identify whether there appears to be a two-way relationship for each of the two-way combination of variables: Quantity & TotalDue, Quantity & max_temp, and TotalDue & max_temp. __

```{r}
plot(df_final[,c('Quantity', 'TotalDue', 'MaxTemp')], cex = 0.3)
summary(df_final$MaxTemp)
```

**Answer:** Two-Way Relationship Comparison

1. Quantity & TotalDue: A positive correlation can be observed between these two variables, so a higher Quantity means a higher TotalDue. 

2. Quantity & Max_Temp:  For the most part, there is a neutral correlation observed between Quantity and Max_Temp, however, there are three high peaks in Quantity when temp are around high 20's, 60, and high 90 degrees, which indicate there are certain temperatures that drive grocery sales. When you live in an area with 4 seasons, there is a buying behavior that's due to the temperatures outside. For the high 20's, during the first sign of low winter temperature, people tend to buy more groceries so they can bunker down inside. Around the first sign of spring, people start to go out more since weather is getting warmer, so there is a spike in the groceries around 60s. For high 90's, it's hot outside and people may celebrate around the pool and have BBQ.

3. TotalDue & Max_Temp: Similar to two-way relationship for Quantity & Max_Temp, TotalDue & Max_Temp have a similar correlation. When people purchase a higher Quantity in groceries, it will result in higher TotalDue.  Around 60's and high 90's, there are high spikes in TotalDue that we've noticed in Quantity, however, depending on the prices of these Quantities, the TotalDue will vary.   