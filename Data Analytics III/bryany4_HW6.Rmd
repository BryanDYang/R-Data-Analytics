---
title: "Module 6 Individual Assignment"
author: "Bryan Yang"
date: "`r Sys.Date()`"
output: html_document
---

# Overview       

In addition to being concerned about profit (as discussed in class), NANSE is concerned about predicting higher traffic in its stores. That is, NANSE wants to predict which weeks and stores will sell above the median number of units.       

Use the code discussed in class to examine the effect of the same variables used in class to predict the target variable `high_med_units` (as discussed in the data description sheet listed above, this variable is an indicator variable that equals 1 when the number of units sold for that store for that week was above the median and 0 otherwise).          

Suggestion: While you could just cut and paste the code used in the live session for this module, we encourage you to write all of the code from scratch. This is a technique we often use when looking up and using new code we are borrowing from someone else.         

# 1.0 Load and summarize   
## Initial loading of data, pacakges, and functions   

```{r}
#Run reusable confusion matrix function
my_confusion_matrix <- function(cf_table) {
  true_positive <- cf_table[4]
  true_negative <- cf_table[1]
  false_positive <- cf_table[2]
  false_negative <- cf_table[3]
  accuracy <- (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)
  sensitivity_recall <- true_positive / (true_positive + false_negative)
  specificity_selectivity <- true_negative / (true_negative + false_positive)
  precision <- true_positive / (true_positive + false_positive)
  neg_pred_value <- true_negative / (true_negative + false_negative)
  print(cf_table)
  my_list <- list(sprintf("%1.0f = True Positive (TP), Hit", true_positive),
                  sprintf("%1.0f = True Negative (TN), Rejection", true_negative),
                  sprintf("%1.0f = False Positive (FP), Type 1 Error", false_positive),
                  sprintf("%1.0f = False Negative (FN), Type 2 Error", false_negative),
                  sprintf("%1.4f = Accuracy (TP+TN/(TP+TN+FP+FN))", accuracy),
                  sprintf("%1.4f = Sensitivity, Recall, Hit Rate, True Positive Rate (How many positives did the model get right? TP/(TP+FN))", sensitivity_recall),
                  sprintf("%1.4f = Specificity, Selectivity, True Negative Rate (How many negatives did the model get right? TN/(TN+FP))", specificity_selectivity),
                  sprintf("%1.4f = Precision, Positive Predictive Value (How good are the model's positive predictions? TP/(TP+FP))", precision),
                  sprintf("%1.4f = Negative Predictive Value (How good are the model's negative predictions? TN/(TN+FN)", neg_pred_value)
                  )
  return(my_list)
}

```

## Install and load packages 

```{r}
library(tidyverse)

#load data
df <- read_rds('mod6HE_logit.rds')

#explore the data
summary(df)
```

# 2.0 Run the Logistic Algorithm
## Prepare the data

```{r}
logit1 <- df %>%
  ungroup() %>%
  select(store, week, high_med_rev, high_med_units, high_med_gpm)

#for use in the model
logit2 <- df %>%
  ungroup() %>%
  select(high_med_gp, high_med_units, size, region, promo_units_per, altbev_units_per, confect_units_per, salty_units_per, velocityA_units_per, velocityB_units_per, velocityC_units_per, velocityD_units_per, velocityNEW_units_per)

# check if "positive" is last for the 'my_confusion_matrix' to work
contrasts(factor(logit2$high_med_units))
```
## Partition the data into testing and training datasets

```{r}
library(caret)
set.seed(77)
partition <- caret::createDataPartition(y=logit2$high_med_units, p=.75, list=F)
data_train <- logit2[partition,]
data_test <- logit2[-partition,]
```

## Train the multivariate model - the instructions part of machine learning

```{r}
model_train <- glm(high_med_units ~ ., family=binomial, data=data_train)
summary(model_train)
```
## Predict the response variable (Use the instructions to predict the likelihood of high gross profit)

```{r}
predict_test <- predict(model_train, newdata=data_test, type='response')
```

## Form table to look at the accuracy of the model

```{r}
table2 <- table(predict_test > .5, data_test$high_med_units) #prediction on left and truth on top
my_confusion_matrix(table2)
```

# 3.0 Use the predictions above to help the business
## Put the data back together for future use

```{r}
#put the prediction back into the test data
data_test$prediction <- predict_test

#create a varaible that shows if the prediction was correct
#(we have to do the classification--in 'round(prediction)'--since logistic regression gives us a probability)
data_test <- data_test %>% mutate(correct_prediction = if_else(round(prediction) == high_med_units, 'correct','WRONG!'))

#add back the original data
temp1 <- logit1[-partition, ]
full_test <- bind_cols(temp1, data_test)

#for viewing
full_test <- full_test %>%
  select(store, week, high_med_gp, high_med_units...4, high_med_units...7, prediction, correct_prediction, size, region, promo_units_per, salty_units_per)
slice_sample(full_test, n=10)
```


# Question & Answer

1. a.(0.5 points) What feature/variable has the most negative statistically significant coefficient on the trained model summary?

**From the trained model summary, Region Ontario (dummy variable) has the most negative statistically significant coefficient of -19.428 with 0.0024p-value.**

1. b.(1 point) Does selling a higher proportion of alternative beverages increase, decrease, or neither increase nor decrease the chance of having above median units sold, holding all other independent variables constant? Write a sentence or two about how you know this?

**Selling a higher proportion of alternative beverages decrease the chance of having above median units sold. From the trained model summary, altbev_units_per shows -5.59 as coefficient with p-value less than 0.01.**

1. c.(1 point) Does selling a higher proportion of velocity B units increase, decrease, or neither increase nor decrease the chance of having above median units sold, holding all other independent variables constant? Write a sentence or two about how you know this?

**Selling a higher proportion of velocity B units neither increase nor decrease the chance of having above median units sold, holding all other independent variables constant. Velocity B_units_per shows the 1.38 as coefficient. However, this coefficient is not statistically significant with p-value close to 1.**

1. d.(0.5 points) Examine the accuracy of the predictions on the test data by answering whether there are more true positives or more true negatives?

**Based on the my_confusion_matrix, the model has 95.19% accuracy. There are 1182 true negatives and 1214 true positives. Therefore there are more true positives than true negatives.**

2. (1 point) In the model training step, which data—training or testing—do we use and why (that is, use two or three sentences to explain why we split the data into training and testing subsets)?

**We split the data into training and testing subsets to go through the process of inferring(training through multivariate model), predicting and back-testing. Meaning, we trained the model using the 75% of the data set. After which, we ran a predictive model based on the training to back-test the validity of the model.**

3. (1 point) The feature `region` has changed in the summary of the trained model. Further, only three regions show up in the summary of the model. The reasoning for this is that the `glm()` function automatically recognizes that `region` is a categorical variable (specifically a factor in R). This is discussed in our Coursera content. Thus, the `glm()` function has created “dummy variables” for the levels of `region`. Which level of the variable is not present here but rather accounted for in the intercept term?

**Region Ontario is not present in the summary of the model but rather accounted for in the intercept term.**

4. (1 point) Interpret the confusion matrix using the test / holdout data. Specifically, which of the four measures, Sensitivity, Specificity, Precision, or Negative Predictive Value has the highest value? Write a sentence that translates this value into words. That is, say something that starts like this: “this means this model is relatively good at predicting...”.

**The sensitivity has the highest value with 0.9529. This means this model is relatively good at predicting True Positive Rate (How many positives did the model get right? TP/(TP+FN)).**

5.  Interpret the confusion matrix. Specifically, which of the four measures, Sensitivity, Specificity, Precision, or Negative Predictive Value has the lowest value? Write a sentence that translates this value into words. That is say something that starts like this: “this means this model is not as good at predicting…”.

**The specificity has the lowest value with 0.9509. This means that this model is not as good at predicting True Negative Rate (How many negatives did the model get right? TN/(TN+FP)).**

6. (2 points) Interpret the confusion matrix. In NANSE’s business setting, which of these measures does NANSE care about the most, sensitivity, specificity, precision, negative predictive value, or something else? Defend your answer in two or three sentences. There is no correct answer here, but you must successfully defend your answer using concepts learned in class to get credit.

**It would be depended on what NANSE is trying to accomplish. Based on the confusion matrix, I think NANSE should care the most about the most accurate figures to trust which would be the sensitivity (predicting True Positive Rate) because other predictive values have more margin for errors. It is notable also, based on the last code chuck for the full test, we need to look at where the model is failing to improve the model in the future.**

